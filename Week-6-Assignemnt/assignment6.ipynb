{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7a693d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36028211",
   "metadata": {},
   "source": [
    "### 1. Load and Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ef3bfe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded. Shape: (891, 15)\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   survived     891 non-null    int64   \n",
      " 1   pclass       891 non-null    int64   \n",
      " 2   sex          891 non-null    object  \n",
      " 3   age          714 non-null    float64 \n",
      " 4   sibsp        891 non-null    int64   \n",
      " 5   parch        891 non-null    int64   \n",
      " 6   fare         891 non-null    float64 \n",
      " 7   embarked     889 non-null    object  \n",
      " 8   class        891 non-null    category\n",
      " 9   who          891 non-null    object  \n",
      " 10  adult_male   891 non-null    bool    \n",
      " 11  deck         203 non-null    category\n",
      " 12  embark_town  889 non-null    object  \n",
      " 13  alive        891 non-null    object  \n",
      " 14  alone        891 non-null    bool    \n",
      "dtypes: bool(2), category(2), float64(2), int64(4), object(5)\n",
      "memory usage: 80.7+ KB\n",
      "None\n",
      "\n",
      "Target distribution:\n",
      "0    549\n",
      "1    342\n",
      "Name: survived, dtype: int64\n",
      "\n",
      "Missing values after preprocessing:\n",
      "survived    0\n",
      "pclass      0\n",
      "sex         0\n",
      "age         0\n",
      "sibsp       0\n",
      "parch       0\n",
      "fare        0\n",
      "embarked    0\n",
      "alone       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = sns.load_dataset('titanic')\n",
    "print(\"Dataset loaded. Shape:\", df.shape)\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nTarget distribution:\")\n",
    "print(df['survived'].value_counts())\n",
    "\n",
    "# Drop irrelevant columns\n",
    "df.drop(['deck', 'embark_town', 'alive', 'who', 'adult_male', 'class'], axis=1, inplace=True)\n",
    "\n",
    "# Drop rows with missing target\n",
    "df.dropna(subset=['survived'], inplace=True)\n",
    "\n",
    "# Fill missing values\n",
    "df['age'] = df['age'].fillna(df['age'].median())\n",
    "df['embarked'] = df['embarked'].fillna(df['embarked'].mode()[0])\n",
    "\n",
    "print(f\"\\nMissing values after preprocessing:\\n{df.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29635c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final dataset shape: (891, 9)\n",
      "Features: ['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked', 'alone']\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical value\n",
    "cat_cols = df.select_dtypes(include='object').columns\n",
    "le = LabelEncoder()\n",
    "for col in cat_cols:\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "print(f\"\\nFinal dataset shape: {df.shape}\")\n",
    "print(f\"Features: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874a7d89",
   "metadata": {},
   "source": [
    "### 2. Feature and Target Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60e9a9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature matrix shape: (891, 8)\n",
      "Target vector shape: (891,)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('survived', axis=1)\n",
    "y = df['survived']\n",
    "\n",
    "print(f\"\\nFeature matrix shape: {X.shape}\")\n",
    "print(f\"Target vector shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14aa37a",
   "metadata": {},
   "source": [
    "### 3. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10e8d542",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddbc9b3",
   "metadata": {},
   "source": [
    "### 4. Train Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "040992c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation Metrics:\n",
      "\n",
      "\n",
      "Logistic Regression\n",
      "Accuracy:  0.7989\n",
      "Precision: 0.7714\n",
      "Recall:    0.7297\n",
      "F1 Score:  0.7500\n",
      "Confusion Matrix:\n",
      "[[89 16]\n",
      " [20 54]]\n",
      "\n",
      "Random Forest\n",
      "Accuracy:  0.8268\n",
      "Precision: 0.8028\n",
      "Recall:    0.7703\n",
      "F1 Score:  0.7862\n",
      "Confusion Matrix:\n",
      "[[91 14]\n",
      " [17 57]]\n",
      "\n",
      "SVM\n",
      "Accuracy:  0.8156\n",
      "Precision: 0.8060\n",
      "Recall:    0.7297\n",
      "F1 Score:  0.7660\n",
      "Confusion Matrix:\n",
      "[[92 13]\n",
      " [20 54]]\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'SVM': SVC()\n",
    "}\n",
    "\n",
    "print(\"Model Evaluation Metrics:\\n\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    if name == 'SVM':\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    pre = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"\\n{name}\")\n",
    "    print(f\"Accuracy:  {acc:.4f}\")\n",
    "    print(f\"Precision: {pre:.4f}\")\n",
    "    print(f\"Recall:    {rec:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4931479e",
   "metadata": {},
   "source": [
    "### 5. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "408abc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Logistic Regression Params (GridSearchCV): {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression - GridSearchCV\n",
    "log_params = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear']\n",
    "}\n",
    "\n",
    "grid_lr = GridSearchCV(LogisticRegression(), log_params, cv=5, scoring='accuracy')\n",
    "grid_lr.fit(X_train_scaled, y_train)\n",
    "print(\"\\nBest Logistic Regression Params (GridSearchCV):\", grid_lr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2a2990a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest Params (RandomizedSearchCV): {'n_estimators': 50, 'min_samples_split': 5, 'max_depth': 6}\n"
     ]
    }
   ],
   "source": [
    "# Random Forest - RandomizedSearchCV\n",
    "rf_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [4, 6, 8, 10],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "random_rf = RandomizedSearchCV(RandomForestClassifier(random_state=42), rf_params, n_iter=10, cv=5, scoring='accuracy', random_state=42)\n",
    "random_rf.fit(X_train, y_train)\n",
    "print(\"Best Random Forest Params (RandomizedSearchCV):\", random_rf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b335b55d",
   "metadata": {},
   "source": [
    "### 6. Final Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16e49590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Tuned Model Performance:\n",
      "\n",
      "\n",
      "Logistic Regression (Tuned)\n",
      "Accuracy:  0.7933\n",
      "Precision: 0.7761\n",
      "Recall:    0.7027\n",
      "F1 Score:  0.7376\n",
      "\n",
      "Random Forest (Tuned)\n",
      "Accuracy:  0.8268\n",
      "Precision: 0.8525\n",
      "Recall:    0.7027\n",
      "F1 Score:  0.7704\n",
      "\n",
      "SVM\n",
      "Accuracy:  0.8156\n",
      "Precision: 0.8060\n",
      "Recall:    0.7297\n",
      "F1 Score:  0.7660\n"
     ]
    }
   ],
   "source": [
    "final_models = {\n",
    "    'Logistic Regression (Tuned)': grid_lr.best_estimator_,\n",
    "    'Random Forest (Tuned)': random_rf.best_estimator_,\n",
    "    'SVM': SVC()\n",
    "}\n",
    "\n",
    "print(\"\\nFinal Tuned Model Performance:\\n\")\n",
    "\n",
    "for name, model in final_models.items():\n",
    "    if name == 'SVM':\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    pre = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"\\n{name}\")\n",
    "    print(f\"Accuracy:  {acc:.4f}\")\n",
    "    print(f\"Precision: {pre:.4f}\")\n",
    "    print(f\"Recall:    {rec:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081eb66b",
   "metadata": {},
   "source": [
    "# Assignment Summary:\n",
    "- Trained 3 models: Logistic Regression, Random Forest, SVM\n",
    "- Evaluated using accuracy, precision, recall, F1-score\n",
    "- Applied GridSearchCV and RandomizedSearchCV\n",
    "- Selected best model based on evaluation metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
